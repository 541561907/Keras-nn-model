{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "loading vocab and processing data\n",
      "loading vocab and processing data\n",
      "(19997, 'train sequences')\n",
      "(104, 'test sequences')\n",
      "Pad sequences (samples x time)\n",
      "('x_train shape:', (19997, 400))\n",
      "('x_test shape:', (104, 400))\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 398, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.1926 - f1score: 0.0507   \n",
      "Epoch 2/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.1511 - f1score: 0.1589   \n",
      "Epoch 3/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.1356 - f1score: 0.2059   \n",
      "Epoch 4/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.1263 - f1score: 0.2386   \n",
      "Epoch 5/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.1161 - f1score: 0.2782   \n",
      "Epoch 6/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.1072 - f1score: 0.2996   \n",
      "Epoch 7/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0950 - f1score: 0.3515   \n",
      "Epoch 8/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0834 - f1score: 0.3923   \n",
      "Epoch 9/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0744 - f1score: 0.4555   \n",
      "Epoch 10/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0635 - f1score: 0.4849   \n",
      "Epoch 11/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0562 - f1score: 0.5189   \n",
      "Epoch 12/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0512 - f1score: 0.5371   \n",
      "Epoch 13/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0454 - f1score: 0.5556   \n",
      "Epoch 14/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0442 - f1score: 0.5780   \n",
      "Epoch 15/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0396 - f1score: 0.6065   \n",
      "Epoch 16/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0364 - f1score: 0.6148   \n",
      "Epoch 17/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0342 - f1score: 0.6213   \n",
      "Epoch 18/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0348 - f1score: 0.6289   \n",
      "Epoch 19/60\n",
      "19997/19997 [==============================] - 139s - loss: 0.0314 - f1score: 0.6167   \n",
      "Epoch 20/60\n",
      "19997/19997 [==============================] - 139s - loss: 0.0308 - f1score: 0.6310   \n",
      "Epoch 21/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0299 - f1score: 0.6617   \n",
      "Epoch 22/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0281 - f1score: 0.6409   \n",
      "Epoch 23/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0274 - f1score: 0.6484   \n",
      "Epoch 24/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0270 - f1score: 0.6646   \n",
      "Epoch 25/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0259 - f1score: 0.6592   \n",
      "Epoch 26/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0241 - f1score: 0.6855   \n",
      "Epoch 27/60\n",
      "19997/19997 [==============================] - 139s - loss: 0.0259 - f1score: 0.6708   \n",
      "Epoch 28/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0241 - f1score: 0.6518   \n",
      "Epoch 29/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0226 - f1score: 0.6694   \n",
      "Epoch 30/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0220 - f1score: 0.7006   \n",
      "Epoch 31/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0262 - f1score: 0.6625   \n",
      "Epoch 32/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0218 - f1score: 0.6896   \n",
      "Epoch 33/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0207 - f1score: 0.6989   \n",
      "Epoch 34/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0230 - f1score: 0.6871   \n",
      "Epoch 35/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0210 - f1score: 0.6818   \n",
      "Epoch 36/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0215 - f1score: 0.6931   \n",
      "Epoch 37/60\n",
      "19997/19997 [==============================] - 139s - loss: 0.0194 - f1score: 0.6811   \n",
      "Epoch 38/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0203 - f1score: 0.6936   \n",
      "Epoch 39/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0192 - f1score: 0.7011   \n",
      "Epoch 40/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0196 - f1score: 0.6821   \n",
      "Epoch 41/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0208 - f1score: 0.6960   \n",
      "Epoch 42/60\n",
      "19997/19997 [==============================] - 139s - loss: 0.0184 - f1score: 0.6923   \n",
      "Epoch 43/60\n",
      "19997/19997 [==============================] - 139s - loss: 0.0201 - f1score: 0.6871   \n",
      "Epoch 44/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0184 - f1score: 0.7170   \n",
      "Epoch 45/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0186 - f1score: 0.6964   \n",
      "Epoch 46/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0159 - f1score: 0.7179   \n",
      "Epoch 47/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0168 - f1score: 0.7120   \n",
      "Epoch 48/60\n",
      "19997/19997 [==============================] - 139s - loss: 0.0170 - f1score: 0.6973   \n",
      "Epoch 49/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0169 - f1score: 0.7078   \n",
      "Epoch 50/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0174 - f1score: 0.7102   \n",
      "Epoch 51/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0145 - f1score: 0.7232   \n",
      "Epoch 52/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0177 - f1score: 0.7085   \n",
      "Epoch 53/60\n",
      "19997/19997 [==============================] - 139s - loss: 0.0162 - f1score: 0.7270   \n",
      "Epoch 54/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0181 - f1score: 0.7029   \n",
      "Epoch 55/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0140 - f1score: 0.7304   \n",
      "Epoch 56/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0162 - f1score: 0.7174   \n",
      "Epoch 57/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0142 - f1score: 0.7222   \n",
      "Epoch 58/60\n",
      "19997/19997 [==============================] - 139s - loss: 0.0156 - f1score: 0.7296   \n",
      "Epoch 59/60\n",
      "19997/19997 [==============================] - 140s - loss: 0.0144 - f1score: 0.7267   \n",
      "Epoch 60/60\n",
      "19997/19997 [==============================] - 141s - loss: 0.0157 - f1score: 0.7240   \n",
      "F1 Score: 52.11%\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras import backend as K\n",
    "\n",
    "from utils import TextLoader\n",
    "\n",
    "utils_dir = 'utils'\n",
    "data_path = 'data/data_2w_arti_clean.csv'\n",
    "test_data_path = 'data/data_test_arti_1_clean.csv'\n",
    "\n",
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 100\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    num_tp = K.sum(y_true*y_pred)\n",
    "    num_fn = K.sum(y_true*(1.0-y_pred))\n",
    "    num_fp = K.sum((1.0-y_true)*y_pred)\n",
    "    num_tn = K.sum((1.0-y_true)*(1.0-y_pred))\n",
    "    #print num_tp, num_fn, num_fp, num_tn\n",
    "    f1 = 2.0*num_tp/(2.0*num_tp+num_fn+num_fp)\n",
    "    return f1\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "data_loader = TextLoader(True, utils_dir, data_path, batch_size, 20, None, None)\n",
    "data_test_loader = TextLoader(True, utils_dir, test_data_path, batch_size, 20, None, None)\n",
    "\n",
    "x_train = data_loader.tensor_xa\n",
    "y_train = data_loader.tensor_y\n",
    "\n",
    "x_test = data_test_loader.tensor_xa\n",
    "y_test = data_test_loader.tensor_y\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[f1score])\n",
    "\n",
    "print(model.summary())\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"F1 Score: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
